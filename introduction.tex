Deep Learning has proliferated over the last decade because of its very profound impact on a wide range of several application areas, namely computer vision[x], speech recognition[x], and natural language processing[x]. In order to put research ideas into practice, advances in deep learning frameworks are a considerable need for the implementation of artificial neural networks (ANNs). Therefore, some frameworks are developed to meet the need, such as Caffe, TensorFlow, Theano, Torch and so on. 

Recent years have witnessed a rapid growth of High Performance Computing field with the advent of new high-end supercomputers which have incredible computational power [x]. Most of the supercomputers take advantage of accelerators, such as Graphic Processing Unit (GPU) or Intel Xeon Phi coprocessor. In addition, most researchers and programmers run deep learning applications on systems consisting of GPU. There are just a few deep learning frameworks, like Caffe, TensorFlow, Theano and Neon[x], which can currently be run on infrastructure including Intel Xeon Phi coprocessor. Unfortunately, the frameworks can only be run on systems including Intel Xeon Phi Knights Landing but not for Knights Corner. Consequently, few deep learning frameworks can be run on several legacy systems, such as [?]Tiane-2 (MilkyWay-2), Thunder, cascade and so forth. This leads to the fact that it is difficult to exploit fully computational power of the underlying hardware platform in case it is not in use. For that reason, the need for developing a novel framework which can be run on such legacy systems is very significant. However, in this paper, our goal is to develop a flexible library which can straightforwardly be integrated into deep learning frameworks rather than a new deep learning one.

pyMIC [x] is a Python module for offloading compute kernels from a Python program to the Intel Xeon Phi Knights Corner coprocessor. Currently, it can simply be leveraged in several scientific computing applications, such as the Python-based open source electronic-structure simulation software GPAW[x] and the open-source high-order accurate computational fluid dynamics solver for unstructured grids PyFR [x]. In this paper, we present pyMIC2, the next generation of pyMIC with the aim of developing a library supporting Intel Xeon Phi Knights Corner coprocessor for deep learning frameworks. pyMIC2 is expanded from pyMIC by implementing functions similar to NumPy[x] to adapt it in order to deep learning frameworks by dint of flexible and layered characteristics of pyMIC. 

pyMIC2 mainly provides a myriad of NumPy-like rudimentary functions, like equal, or, abs, mean, sum and so on. Furthermore, pyMIC2 improves significantly several existing functions of pyMIC in the performance aspect via vectorization mechanism. The functions of pyMIC2 can directly be run on Intel Xeon Phi Knights Corner coprocessor by dint of offloading mechanism. Besides, they facilities high-level functions used as block buildings in establishment of ANNs, such as activate function, loss function, accuracy function and so forth.

We evaluate pyMIC2 with regard to two aspects: (1) discrepancy in performance in comparison with NumPy and (2) feasibility of pyMIC2 when integrating it into the well-known deep learning framework Chainer. Experimental results demonstrate that pyMIC2 outperforms NumPy in terms of computation time when considering them based on two different hardware platforms with same theoretical performance. Given such effectiveness of performance aspect, we conclude that pyMIC2 is a flexible but effective library which is highly integrated to deep learning frameworks.

In brief, this work makes the following contributions:
\begin{itemize}
\item We optimize several existing functions of pyMIC so as to increase program performance.
\item We implement pyMIC2 which is extended from pyMIC by means of implementing some numpy-like functions so that it can facilitate greatly several deep learning frameworks run on the legacy systems containing Intel Xeon Phi Knights Corner coprocessor. Therefore, researchers and programmers can closely integrate pyMIC2 into their interesting deep learning framework.
\item We try to integrate pyMIC2 into the well-known framework Chainer [x] and evaluate the effectiveness as well as flexibility of pyMIC2.
\end{itemize}

The remainder of the paper is organized as follows. The next section reviews in detail the underlying architecture of Intel Xeon Phi Knights Corner coprocessor and the structure of pyMIC module. Section 3 describes the implementation of pyMIC2 based on pyMIC. The experimental results so as to evaluate the effectiveness of pyMIC2 compared with NumPy as well as the practical integration of pyMIC2 and Chainer are elaborated in Section 4. Finally, Section 5 gives some conclusions and the further enhancement of the study.