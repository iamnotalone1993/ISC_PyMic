\begin{thebibliography}{10}
\providecommand{\url}[1]{\texttt{#1}}
\providecommand{\urlprefix}{URL }

\bibitem{backprop}
Backpropagation algorithm.
  \url{http://deeplearning.stanford.edu/wiki/index.php/Backpropagation_Algorithm}

\bibitem{caffe}
Caffe. \url{http://caffe.berkeleyvision.org}

\bibitem{deep-frame-mic}
Deep learning frameworks for intel xeon phi.
  \url{https://software.intel.com/en-us/ai-academy/frameworks}

\bibitem{docker}
Docker: Build, ship, and run any app, anywhere. \url{https://www.docker.com}

\bibitem{bigmempage}
How to use huge pages to improve application performance on intel® xeon phi
  coprocessor.
  \url{https://software.intel.com/sites/default/files/Large_pages_mic.pdf}

\bibitem{mathlib}
Overview: Intel® math library.
  \url{https://software.intel.com/en-us/node/522653}

\bibitem{pymic}
pymic: A python offload module for the intel(r) xeon phi(tm) coprocessor.
  \url{https://software.intel.com/en-us/articles/pymic-a-python-offload-module-for-the-intelr-xeon-phitm-coprocessor}

\bibitem{tensorflow}
Tensorflow. \url{https://www.tensorflow.org}

\bibitem{mnist}
The mnist database of handwritten digits.
  \url{http://yann.lecun.com/exdb/mnist}

\bibitem{theano}
Theano. \url{http://deeplearning.net/software/theano}

\bibitem{threadaffinity}
Thread affinity interface. \url{https://software.intel.com/en-us/node/522691}

\bibitem{top500}
Top500 supercomputing sites. \url{https://www.top500.org}

\bibitem{torch}
Torch: A scientific computing framework for luajit. \url{http://torch.ch}

\bibitem{Chainer}
Chainer: a deep learning framework. \url{https://chainer.org} (2017)

\bibitem{Numpy}
Numpy. \url{http://www.numpy.org} (2017)

\bibitem{collobert2011natural}
Collobert, R., Weston, J., Bottou, L., Karlen, M., Kavukcuoglu, K., Kuksa, P.:
  Natural language processing (almost) from scratch. Journal of Machine
  Learning Research  12(Aug),  2493--2537 (2011)

\bibitem{ding2014theano}
Ding, W., Wang, R., Mao, F., Taylor, G.: Theano-based large-scale visual
  recognition with multiple gpus. arXiv preprint arXiv:1412.2302  (2014)

\bibitem{hannun2014deep}
Hannun, A., Case, C., Casper, J., Catanzaro, B., Diamos, G., Elsen, E.,
  Prenger, R., Satheesh, S., Sengupta, S., Coates, A., et~al.: Deep speech:
  Scaling up end-to-end speech recognition. arXiv preprint arXiv:1412.5567
  (2014)

\bibitem{phibook}
Jeffers, J., Reinders, J.: Intel xeon phi coprocessor high performance
  programming, 2013. Journal of Computer Science \& Technology

\bibitem{klemm2014pymic}
Klemm, M., Enkovaara, J.: pymic: A python offload module for the intel xeon phi
  coprocessor. Proceedings of PyHPC  (2014)

\bibitem{klemm2016using}
Klemm, M., Witherden, F., Vincent, P.: Using the pymic offload module in pyfr.
  arXiv preprint arXiv:1607.00844  (2016)

\bibitem{krizhevsky2012imagenet}
Krizhevsky, A., Sutskever, I., Hinton, G.E.: Imagenet classification with deep
  convolutional neural networks. In: Advances in neural information processing
  systems. pp. 1097--1105 (2012)

\bibitem{russakovsky2015imagenet}
Russakovsky, O., Deng, J., Su, H., Krause, J., Satheesh, S., Ma, S., Huang, Z.,
  Karpathy, A., Khosla, A., Bernstein, M., et~al.: Imagenet large scale visual
  recognition challenge. International Journal of Computer Vision  115(3),
  211--252 (2015)

\bibitem{tokui2015chainer}
Tokui, S., Oono, K., Hido, S., Clayton, J.: Chainer: a next-generation open
  source framework for deep learning. In: Proceedings of workshop on machine
  learning systems (LearningSys) in the twenty-ninth annual conference on
  neural information processing systems (NIPS). vol.~5 (2015)

\bibitem{colfaxbook}
Vladimirov, A., Asai, R., Karpusenko, V.: Parallel Programming and Optimization
  with Intel Xeon Phi Coprocessors: Handbook on the Development and
  Optimization of Parallel Applications for Intel Xeon Processors and Intel
  Xeon Phi Coprocessors. Colfax International (2015)

\end{thebibliography}
